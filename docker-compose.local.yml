services:
  # YouTube Transcription API with built-in Whisper
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
    container_name: v-transcribe-api
    volumes:
      - ./transcripts:/data
      - /tmp:/tmp
    networks:
      - transcribe-net
    deploy:
      resources:
        limits:
          memory: 1200M   # More memory for built-in whisper
        reservations:
          memory: 600M    # Reserve sufficient memory

  # Frontend (serves static files + proxy)
  web:
    image: nginx:alpine
    container_name: v-transcribe-web
    ports:
      - "8080:80"  # Access at http://localhost:8080
    volumes:
      - ./frontend:/usr/share/nginx/html:ro
      - ./transcripts:/var/www/files:ro
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - api
    networks:
      - transcribe-net

networks:
  transcribe-net:
    driver: bridge

volumes:
  whisper-models:
  whisper-cache:  # For faster-whisper model cache
  transcripts: