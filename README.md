# YouTube Transcription Service

A self-hosted YouTube transcription service built with Go, HTMX, and Docker Compose. Downloads YouTube videos, extracts audio, and generates transcripts using OpenAI Whisper.

## Features

- ğŸ¥ Download audio from YouTube videos using yt-dlp
- âš¡ **Fast transcription** using optimized Whisper tiny model (5-10x faster)
- ğŸ™ï¸ High-quality transcription using OpenAI Whisper
- ğŸ“± Beautiful, responsive web interface with HTMX
- ğŸ“ Download both audio and transcript files
- ğŸ“‹ Copy transcripts to clipboard with feedback
- ğŸ³ Easy deployment with Docker Compose
- ğŸ“Š Real-time progress tracking with separate audio/transcription phases
- ğŸ”„ **Job persistence** - survives restarts and continues processing
- ğŸ›¡ï¸ **Reliable processing** with retry logic and timeout handling

## Prerequisites

- Docker â‰¥ 25 & docker-compose plugin
- **2GB RAM minimum** for `tiny` model, 4GB recommended
- Ubuntu/Linux environment

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <your-repo> && cd v-transcribe
   ```

2. **Start the services**:
   ```bash
   docker compose up -d --build
   ```

3. **Access the application**:
   Open http://localhost in your browser

4. **Use the service**:
   - Paste a YouTube URL
   - Click "Transcribe"
   - Wait for processing to complete
   - Copy text or download the transcript file

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    POST /job        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontendâ”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Go API      â”‚
â”‚  (HTMX)  â”‚  job-id JSON        â”‚  container    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚ (yt-dlp +     â”‚
â–²    GET /job/:id           â”‚  ffmpeg)      â”‚
â”‚  transcript / download    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                  â”‚ WAV
â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  HTTP (OpenAI-style)   â–¼
â”‚ go-whisper   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ model server â”‚      text / srt
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Services

- **nginx**: Serves frontend and handles file downloads
- **api**: Go backend for job management and orchestration  
- **whisper**: OpenAI Whisper transcription service

## Configuration

### Environment Configuration

The application uses a structured configuration approach:

- **`config/default.env`**: Non-secret defaults (committed to repo)
- **`config/secrets.env.example`**: Template for secrets (committed to repo)
- **`config/secrets.env`**: Your actual secrets (ignored by git)

Environment files are loaded in order: defaults first, then secrets override defaults.

### Initial Setup

```bash
# Copy secrets template (done automatically by scripts)
cp config/secrets.env.example config/secrets.env

# Edit with your actual values if needed
nano config/secrets.env
```

### GPU Support (Optional)

For faster transcription with NVIDIA GPU, uncomment the GPU section in `docker-compose.yml`:

```yaml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          capabilities: [gpu]
```

### Model Size

Edit the Whisper model in `docker-compose.yml`:

```yaml
environment:
  - WHISPER_MODEL=ggml-small-q5_0.bin  # For less RAM
  - WHISPER_MODEL=ggml-large-q5_0.bin  # For better accuracy
```

## Development

### Local Go Development

```bash
cd api
go mod tidy
go run main.go
```

### Frontend Development

The frontend is pure HTML/HTMX/Tailwind - just edit `frontend/index.html` and refresh.

## Troubleshooting

### Common Issues

1. **Out of memory**: Use smaller Whisper model (`ggml-small-q5_0.bin`)
2. **YouTube download fails**: Check if yt-dlp needs updating
3. **Transcription fails**: Ensure Whisper service is running and accessible

### Logs

```bash
# View all logs
docker compose logs -f

# View specific service logs
docker compose logs -f api
docker compose logs -f whisper
```

### Cleanup

```bash
# Stop services
docker compose down

# Remove volumes (transcripts and models)
docker compose down -v
```

## File Structure

```
v-transcribe/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.go           # Go backend API
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html        # HTMX frontend
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ default.env       # Non-secret defaults
â”‚   â”œâ”€â”€ secrets.env.example # Secrets template
â”‚   â””â”€â”€ secrets.env       # Your secrets (gitignored)
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ Dockerfile.api    # API container build
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ test_locally.sh   # Local development setup
â”‚   â””â”€â”€ cleanup.sh        # Cleanup script
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ initial.md        # Project requirements  
â”œâ”€â”€ docker-compose.yml    # Full production setup
â”œâ”€â”€ docker-compose.local.yml # Local development setup
â”œâ”€â”€ nginx.conf           # Nginx configuration
â”œâ”€â”€ go.mod               # Go dependencies
â””â”€â”€ README.md           # This file
```

## API Endpoints

- `POST /job` - Submit transcription job
- `GET /job/{id}` - Get job status and results
- `GET /files/{filename}` - Download transcript files

## License

MIT License